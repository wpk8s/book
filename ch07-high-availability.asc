[[ch07-high-availability]]
== High availability

For me, high availability simply means that if part of the infrastructure
fails, the websites still run without problems for visitors, and the only
problem is for me to heal the infrastructure. Ideally, the infrastructure
should self-heal and auto-scale, but that will be the topic of another
book.

MicroK8s starts by default with HA enabled, and starts acting as a real
high available cluster, the minute you add 2 or more extra nodes in the
cluster, as the setup is 3 minimal nodes.

The missing part of default, which might not be needed for some cases, but
mandatory for a WordPress intended cluster, is High Available Storage.

=== Local storage vs high available storage

MicroK8s comes with two alternative storage solution addons, at one step
distance to use any of it.

The one that existed since beginning of the project, LOCAL, allowed
containers to use volumes strictly if they run in the same host.

That has been a blocker for high availability, as if that specific node
crushes, than data would not be available easy to continue running on
other healthy nodes in the cluster.

Since version 1.21, MicroK8s has https://openebs.io/[OpenEBS] as storage
addon, and on any high available cluster with persistent data requirements
this must be your default choice, unless you already know how to handle
alternative solutions.

By alternative solutions, I would look into using the public clouds volume
attachment support in Kubernetes, but for me, it breaks the concept of
being _public cloud vendor free_, although, with some effort, it could be
done. But involves extra time in research, maintenance and so on.

=== Introducing OpenEBS

For High Available storage, OpenEBS on MicroK8s will be the fastest with
minimal maintenance effort you could benefit.

The addon comes with two storage classes, and I want you to remember one
thing: **openebs-jiva-default** is your only choice you need to use to
have self healing containers that can move from node to node without
loosing everything when a node crushes.

It comes with a minimal resource requirement although: minimum 3 nodes in the
cluster. Well, that is also the specification of MicroK8s High Available
cluster. The addon is pre-configured to replicate the volumes on minimal 3
nodes.

From this point, as we will be handling High Available cluster, we will be
using a setup with minimum 3 nodes all the time.

Note: Localpv storage class is available as well. It will still allow any node
to mount a volume from this class, but, the volumes will be locked to the node
they got created. While there is a small performance benefit, in case of
disaster, disaster will be with total unavailability of the affected websites.
I strongly recommend on using Jiva, as node crushes will not be disasters, just
temporary, quickly fixable issues.

**What is OpenEBS offering us?**

OpenEBS provides simply network compatible volumes, with real-time mirroring of
data, so in case of the crush of the node that is storing the data, at least
two other have the identical same data. If a container with a volume attached
to it crushes as of a node failure, it is restarted very quickly on another
node, and the volume is re-attached to it. Even if the node had a copy of the
volumes data, failure is not felt, as the volume can still run from the other
sources. With proper alerting system in place, you could jump in time and fix
the node's issue, or in my preference, I make sure I have the problem logs
available, and simply create a new node in the cluster, and remove the old
broken one. After getting my ideal state of the cluster back, I can now
research in the problem without having the cluster in danger, and the visitors
would not even think there was a problem.

Another advantage of OpenEBS is that one volume could be shared. Meaning we
will be able to use a volume attached to WordPress, spread on multiple nodes
to increase performance on high traffic. We can add nodes, we can remove nodes.
This helps keeping costs lower in time, without causing any downtime as you
need in classic vertical scaling setups.

=== Setting up a Highly Available Cluster

Using the setup we did until now, we can replicate the setup from Chapter 4, at
least 3 times to have minimal 3 nodes available to setup the cluster. Just stop
right before `sudo microk8s enable dns ingress storage`.

The next step we need is to install and enable iscsi daemon, to allow OpenEBS
to work.

On each node, run the following:

[source,bash]
----
sudo apt install open-iscsi
sudo systemctl enable --now iscsid
----

Now, simply, only in one node, first one I usually do, run the command to get
the add node command with token:

`sudo microk8s add-node`

The result should be similar to:

[source,text]
----
From the node you wish to join to this cluster, run the following:
microk8s join 135.181.91.189:25000/f6308cb5dea38cb7c785adfe347a214a/eaf81c74de94

If the node you are adding is not reachable through the default interface you can use one of the following:
 microk8s join 135.181.91.189:25000/f6308cb5dea38cb7c785adfe347a214a/eaf81c74de94
 microk8s join 172.16.0.3:25000/f6308cb5dea38cb7c785adfe347a214a/eaf81c74de94
----

Copy the last line and run it prefixed with `sudo ` on second node.

Repeat the process for each node, first get command with token, second run it
on the new node.

You can have as many nodes you want like this.

Next, on first node, or another one if you would insist, run:

`sudo microk8s enable dns ingress openebs`

It will take some time, up to a minute.

When you are done, if you run `sudo microk8s status` you should have a similar
output:

[source,text]
----
microk8s is running
high-availability: yes
  datastore master nodes: 172.16.0.3:19001 172.16.0.5:19001 172.16.0.2:19001
  datastore standby nodes: 172.16.0.7:19001 172.16.0.6:19001 172.16.0.4:19001
addons:
  enabled:
    dns                  # CoreDNS
    ha-cluster           # Configure high availability on the current node
    helm3                # Helm 3 - Kubernetes package manager
    ingress              # Ingress controller for external access
    openebs              # OpenEBS is the open-source storage solution for Kubernetes
----

The rest of information is about disabled addons, so you can ignore the rest.

The above, shows us we have a cluster of 6 nodes, with 3 masters and 3 worker
nodes that in case of a dead master, any could replace it. With more than 3
nodes I surely sleep well when 1-2 nodes could crush during the night, as long
as the total amount of workload can be sustained by healthy nodes.

Regarding this, I usually calculate that I use 70-80% of amount of resources
and we will talk about how to estimate resources later in the book.

Let's now tweak our original WordPress recipe to sustain WordPress pods
replicated over multiple nodes. When we see them working, we will experiment
manually nodes issues, simulating common problems you might face when for
example, the public cloud provider has issues and certain nodes become
unavailable (we will simply destroy the node, which will be equivalent for our
cluster when node is not available because of the provider).
